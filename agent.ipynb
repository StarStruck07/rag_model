{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "llm = init_chat_model(\"llama3.1\",model_provider = \"Ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "loader = CSVLoader(\n",
    "    file_path = 'nirf_clean.csv',\n",
    "    source_column=\"Name\",\n",
    "    metadata_columns=[\"Rank\",\"State\"],\n",
    ")\n",
    "docs = loader.load()\n",
    "embed = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": device}\n",
    "    )\n",
    "db = Chroma.from_documents(docs,embed,persist_directory=\"./chroma_db\")\n",
    "retiever = db.as_retriever(search_kargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = \"Tavily-key\"\n",
    "from langchain_tavily import TavilySearch\n",
    "search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from langchain_huggingface import HuggingFaceEmbeddings\\nfrom langchain_core.documents import Document\\nfrom accelerate import init_empty_weights\\nembed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",model_kwargs={\"device\": device})\\nresponse = search_tool.invoke({\"query\": \"What was the cutoff for nit trichy cs in 2024?\"})\\nprint(response)\\nraw_docs = response[\\'results\\']\\ndocs = [\\n    Document(page_content=res[\\'content\\'],metadata={\"url\": res[\\'url\\']}) for res in raw_docs\\n]\\ndb = Chroma.from_documents(docs,embed,persist_directory=\"chroma_db\")\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from accelerate import init_empty_weights\n",
    "embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",model_kwargs={\"device\": device})\n",
    "response = search_tool.invoke({\"query\": \"What was the cutoff for nit trichy cs in 2024?\"})\n",
    "print(response)\n",
    "raw_docs = response['results']\n",
    "docs = [\n",
    "    Document(page_content=res['content'],metadata={\"url\": res['url']}) for res in raw_docs\n",
    "]\n",
    "db = Chroma.from_documents(docs,embed,persist_directory=\"chroma_db\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    input_key=\"input\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "template = \"\"\"\n",
    "You are an AI agent, specifically modeled to answer questions related to various engineering enterance exams in India.\n",
    "You should ask the user various questions related to his exam scores, branch preferences, interests etc to access his profile, and then reccomend him 3 colleges\n",
    "You must answer all the queires wihh the context provided below:\n",
    "Here is some relevant context form old database : {context}\n",
    "Here is some context taken from web: {web_context}\n",
    "Here is the chat history: {history}\n",
    "Here is the query : {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retiever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a llm agent to help with all your doubts regarding the various diffrent engineering entrance exams in India.Type 'exit' to quit\n",
      "AI: According to the latest updates from IIT Kanpur, the JEE Advanced 2025 exam date has been announced as May 18, 2025.\n",
      "\n",
      "Now, let's move on to your profile. Can you please share your:\n",
      "\n",
      "1. JEE Main score (out of 300) for this year?\n",
      "2. Your preferred branch among Engineering, Architecture, or any other?\n",
      "3. Any specific interests or hobbies that might help me suggest the best colleges for you?\n",
      "AI: Congratulations on scoring a good JEE Main score!\n",
      "\n",
      "To get personalized college recommendations, I need to know more about your profile. Please answer the following questions:\n",
      "\n",
      "1. You mentioned that you scored **216** in JEE Mains. What percentile do you expect to achieve with this score? (You can refer to the web content provided for an idea of percentiles)\n",
      "2. Which branch would you prefer among Civil, Mechanical, Electrical, Computer Science, or any other?\n",
      "3. Do you have any specific interests or hobbies that might help me suggest the best colleges for you?\n",
      "\n",
      "Please answer these questions, and I'll be happy to recommend three colleges that suit your profile!\n",
      "AI: Based on your inputs, let's analyze your profile.\n",
      "\n",
      "**JEE Main Score and Percentile:**\n",
      "You have scored 216 in JEE Mains and expect to achieve a percentile of **99.46**, which is an excellent score!\n",
      "\n",
      "**Branch Preference:**\n",
      "You would like to pursue Computer Science or related branches (Electronics). Based on this preference, I'll consider colleges that offer strong programs in these areas.\n",
      "\n",
      "**Location:**\n",
      "Your preferred location is South India, which helps narrow down the college options to those located in Southern states of India.\n",
      "\n",
      "Considering your profile and preferences, here are three college recommendations for you:\n",
      "\n",
      "1. **International Institute of Information Technology (IIIT), Allahabad**: Although IIIT has multiple campuses, their Hyderabad campus would be a great fit, considering your preference for South India. They offer excellent programs in Computer Science and related branches.\n",
      "2. **National Institute of Technology (NIT), Tiruchirappalli**: Located in the state of Tamil Nadu, NIT Trichy is a well-regarded institute with a strong computer science program. Their campus infrastructure and research opportunities would be an excellent fit for someone with your interests.\n",
      "3. **Birla Institute of Technology and Science (BITS), Pilani - Hyderabad Campus**: As you're interested in Computer Science or related branches, BITS Pilani's Hyderabad campus is worth considering. They offer a wide range of programs in computer science, and their location in South India aligns with your preference.\n",
      "\n",
      "Please let me know if these recommendations meet your expectations!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(res.page_content \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m db_results)\n\u001b[32m     15\u001b[39m web_response = search_tool.invoke({\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m:user_input})\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m raw = \u001b[43mweb_response\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m web_context = [\n\u001b[32m     18\u001b[39m     Document(page_content=res[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m], metadata= {\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: res[\u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m]}) \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m raw\n\u001b[32m     19\u001b[39m ]\n\u001b[32m     20\u001b[39m history_dict = memory.load_memory_variables({})\n",
      "\u001b[31mKeyError\u001b[39m: 'results'"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from accelerate import init_empty_weights\n",
    "\n",
    "print(\"Hello! I am a llm agent to help with all your doubts regarding the various diffrent engineering entrance exams in India.\" \\\n",
    "\"Type 'exit' to quit\")\n",
    "while True:\n",
    "    user_input = input(\"\\nUser: \")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"Exiting conversation.\")\n",
    "        break\n",
    "\n",
    "    db_results = retiever.get_relevant_documents(user_input)\n",
    "    context = \"\\n\".join(res.page_content for res in db_results)\n",
    "\n",
    "    web_response = search_tool.invoke({\"query\":user_input})\n",
    "    raw = web_response['results']\n",
    "    web_context = [\n",
    "        Document(page_content=res['content'], metadata= {\"url\": res['url']}) for res in raw\n",
    "    ]\n",
    "    history_dict = memory.load_memory_variables({})\n",
    "    history = history_dict.get(\"history\", \"\")\n",
    "\n",
    "    response = rag_chain.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"web_context\": web_context,\n",
    "        \"context\": context,\n",
    "        \"history\": history,\n",
    "    })\n",
    "    memory.save_context({\"input\": user_input},{\"output\":response['answer']})\n",
    "    print(f\"AI: {response['answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
